Overall Concept
1. Root Node (User Prompt)
    * The user begins by typing a prompt (e.g., “Design the interface for a 1000-floor elevator”).
    * This text becomes the root node on the Main Canvas, serving as the trunk of a tree from which all subsequent branches of questions extend.
2. AI-Powered Question Generation (via gpt-4-0125-preview)
    * Once the user sets their prompt and initial preferences (e.g., conflict handling), the AI dynamically generates follow-up questions.
    * It references previously provided answers and any uploaded knowledge base documents to decide which child nodes (sub-branches) to create.
    * Early questions are intentionally basic (e.g., “Is the elevator primarily for humans or machinery?”), helping to clarify fundamental requirements before diving deeper.
3. Breadth-First or Depth-First Q&A
    * Depending on user settings, the system organizes question flow in either a breadth-first or depth-first manner.
    * Regardless of the chosen mode, each sibling or child question is generated only after its predecessor is answered—ensuring a sequential experience.
    * The AI may also prune no-longer-relevant paths if a revised answer invalidates them or auto-resolve minor conflicts (if selected).
4. Stopping Criteria & Generation
    * The user may cap the process at a certain number of questions (e.g., “Stop after 20 questions”), prompting the system to offer a mockup at that point.
    * Alternatively, the AI can decide when it has “enough” information to produce a final design.
    * Once the Q&A phase ends, the system compiles a requirements document and produces React/Tailwind code for a working mockup, reflecting all branches explored.

Step 1: Initial Setup & Prompt Node
1. Enter the Prompt
    * The user types: “Design the interface for a 1000-floor elevator.”
    * This becomes the root node on the Main Canvas (labeled “Prompt: 1000-floor elevator”).
2. Optional Knowledge Base Upload (AI-Enhanced Auto-Population)
    * If the user uploads relevant documents (elevator guidelines, building specs, etc.), the AI may auto-populate certain answers where it’s confident.
    * If no knowledge base is uploaded, no auto-populate option appears.
3. Unknown & Conflict Handling (AI Settings)
    * Unknowns:
        * Auto for trivial unknowns – The AI attempts to guess if it detects a minor/low-impact data gap. Major unknowns (like crucial safety codes) always prompt the user.
        * Always prompt – The user must explicitly address each unknown, big or small.
    * Conflicts:
        * Auto-resolve minor conflicts – The AI silently fixes small contradictions (e.g., minor design details), pruning or adjusting the older/less critical node.
        * Manual resolution – All conflicts appear in the Q&A Panel for user input. Major conflicts always require user confirmation.
4. Breadth-First or Depth-First Q&A Selection
    * Q&A Flow: The user chooses Breadth-First or Depth-First.
        * Breadth-First: Completes all top-level siblings first before revealing their children.
        * Depth-First: Immediately dives into child nodes of the just-answered question, delaying siblings until that branch is done.
5. Question Limit or AI-Determined Stop
    * The user may cap the process at a certain number of questions (e.g., 20).
    * Otherwise, the AI decides when to finalize.
Once these settings are confirmed, the root node is finalized on the Main Canvas.

Step 2: Interactive Q&A Flow (AI-Driven)
2.1. The Root Node & First Questions
* Main Canvas: Displays the root node (the user’s prompt).
* Right-Hand Q&A Panel: A “Begin Q&A” button triggers the AI (gpt-4-0125-preview).
* AI Question Generation:
    * The AI checks the user’s prompt (and any knowledge base) to spawn the first top-level questions: Q1, Q2, Q3.
    * For instance:
        * Q1: “Is the elevator primarily for humans or machinery?”
        * Q2: “What is the total number of floors?”
        * Q3: “Is there a known budget constraint?”
2.2. Q&A Progression (Breadth-First or Depth-First)
1. One Question at a Time
    * No new sibling or child question is generated until the current question is answered.
    * If multiple siblings are warranted (Q1, Q2, Q3, Q4), the system only spawns Q2 after Q1 is answered, Q3 after Q2, etc.
2. Breadth-First Mode
    * If the user selected breadth-first, they finish all sibling questions (Q1, Q2, Q3) at the top level.
    * Only after those siblings are answered does the system reveal their child nodes (Q4, Q5, etc.), going layer by layer.
3. Depth-First Mode
    * If the user selected depth-first, as soon as Q1 is answered, the system reveals Q1’s child nodes (Q4, Q5). The user fully explores that branch before returning to Q2 or Q3.
    * This process continues recursively down each branch until no more child questions remain, then moves on to siblings.
4. New Top-Level Branches
    * If the AI identifies a major new topic not covered by existing branches, it can create a new top-level question.
    * Three ways new top-level questions emerge:
        1. User-Initiated – The user explicitly requests a domain not yet addressed.
        2. AI-Detected Mid-Flow – The AI infers a new category (e.g., advanced security) requiring its own node.
        3. Post-Completion – After all known questions are finished, the AI checks for anything missing.
    * Queuing: New top-level topics are typically queued until the user’s current branch/layer is done—unless the user/AI deems it urgent.
2.3. Conflict & Unknown Resolution (AI Assistance)
1. Conflict Detection
    * After every new answer, the AI checks for contradictions vs. prior answers or knowledge-base data.
2. Minor Conflicts (Auto-Resolve)
    * If enabled, the AI silently fixes small mismatches (e.g., kiosk color) by pruning or adjusting the less critical node.
3. Major Conflicts (Always Prompt)
    * If a conflict is significant (e.g., code compliance vs. user preference), the user must reconcile.
    * Example: “Floors above 500 need advanced voice commands” vs. “No voice hardware allowed.”
4. Unknown Fields
    * Trivial Unknown (Auto Mode): The AI guesses, labeling it “AI-guessed.”
    * Major Unknown: The system waits until the user provides data (blocking child questions).
    * “Always prompt” means no auto-fills occur; the user must address every unknown.
2.4. Revisiting & Editing Answers
* Clicking an Answered Node
    * The user can revisit Q2 and change its answer at any time. The system re-checks Q2’s children.
* Pruning & Replacement
    * If the new answer invalidates old children, the system prunes them. It may spawn fresh children if the updated answer leads to different logic.
* Cross-Branch Conflicts
    * If Q2’s edit causes a conflict with Q7 in another branch, the system checks if it’s minor or major. Minor = auto-fix if enabled, major = user decides which node to keep.
2.5. Stopping & Additional Inquiries
1. Max Questions Reached
    * If the user set a limit (e.g., 20), the system says, “You’ve reached 20 questions. Generate a mockup now or continue?”
2. AI Decides
    * If no cap, the AI eventually says, “We likely have enough information for a design. Generate now or more questions?”
3. User-Initiated Topics
    * At any time, the user can say, “I want more detail on accessibility.”
    * The AI spawns additional nodes for that domain or may add a new top-level question if it’s a significant area.

Step 3: Consolidate & Generate
3.1. Requirements Document
* AI Compilation:
    * The system compiles all answered questions (Q1–QX) plus system assumptions, auto-resolved conflicts, and AI guesses.
* Preview & Download:
    * The user can view it in-app, then export as PDF, DOCX, or Markdown.
3.2. Prototype UI Code (React/Tailwind)
* Code Generation:
    * The AI creates a sandboxed React + Tailwind (or HTML/CSS) mockup reflecting final requirements.
    * Users can preview an elevator panel or kiosk layout with the chosen features.
* Copy/Export:
    * A “Copy Code” button allows quick copying.
    * An “Export to Figma” option (via plugin/tokens) supports further design iteration.
3.3. Multiple Versions
* Generate Another Version:
    * If desired, the user can create alternative UI designs—changing styling or layout.
    * They can generate as many versions as they want and flip between them easily.
3.4. Save for Later
* Session Preservation:
    * The system can save the entire Q&A session (root prompt, answers, auto-populated data, conflicts, design previews).
* Local vs. Server Storage:
    * Locally (browser storage) or on the server if user accounts exist.
* Metadata & Session Management:
    * Each saved session includes a custom name, timestamp, and progress.
    * A “My Sessions” area lets users resume, rename, or delete saved sessions.
* Auto-Save & Manual Save:
    * The system periodically auto-saves progress and allows manual “Save” at key points.
    * If the user tries to close without saving, it warns or auto-saves.

Interface Layout Summary
1. Main Canvas (Center)
    * Root Node (Prompt): The user’s initial text, e.g., “1000-floor elevator.”
    * Top-Level Questions (Q1, Q2, Q3): Each major question is a branch from the root.
    * Child Nodes (Q4, Q5, etc.): Appear beneath a parent question.
    * Visual Indicators: Conflict icons for major issues, auto-filled icons for AI guesses.
2. Right-Hand Q&A Panel
    * Always open, showing the current question.
    * Displays AI prompts, conflict/unknown alerts, resolution options.
    * Shows “Auto-Populate” if the AI has enough knowledge to guess confidently.
3. Header / Toolbar (Top)
    * Steps: (1) Setup, (2) Q&A, (3) Generate.
    * A progress bar (e.g., “X / Y questions answered”).
    * Knowledge Base status icon (uploaded or not).
4. Generation/Preview Area
    * Once Q&A ends, a requirements doc preview and a React/Tailwind sandbox appear.
    * Tools to download docs, copy code, or export to design tools.

Graph Impact Summary
1. Overridden Nodes & Children from Conflicts
    * In auto-resolve mode, the AI prunes less critical nodes.
    * Major conflicts prompt user choice. The discarded path is removed.
2. Unknown Answers & Children
    * Auto-mode guesses trivial unknowns, labeled “AI-guessed.”
    * Major unknowns block sub-questions until the user responds.
3. Editing a Parent Node & Branch Replacement
    * If a parent’s answer changes, old children might be pruned.
    * The AI may spawn new children for the revised answer.
    * Branches removed by conflict override don’t return unless the user edits again.
4. Cross-Branch Conflicts from Edited Nodes
    * An edit in Q2 can conflict with Q7 in a different branch.
    * Minor = silent fix (if enabled), major = user must pick which node stands.

Why This Flow Works
1. Prompt as Anchor
    * Keeps the user’s main goal—designing a 1000-floor elevator—front and center.
2. Configurable Q&A Style
    * Users pick breadth-first or depth-first, suiting different preferences or workflows.
3. Sequential Question Generation
    * Ensures the system never overwhelms the user; each new question only appears once the current one is answered.
4. Granular Unknown/Conflict Settings
    * Streamlined approach for minor gaps or mismatches, user-driven resolution for major ones.
5. Flexible Stopping
    * The user (or AI) decides when there’s enough data to produce a final mockup.
6. Requirements & Live Prototype
    * Immediate generation of a functional React/Tailwind concept based on the final Q&A.
7. Multiple Versions & Saved Sessions
    * Rapid iteration on different interface styles, with the option to pause and resume at any time.
By allowing the breadth-first or depth-first choice upfront and generating each follow-up question only after the current one is answered, this system provides a clear, orderly approach to designing even the most complex of UIs—like a 1000-floor elevator—while handling conflicts, unknowns, and new topics in a structured manner.
